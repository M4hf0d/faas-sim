AUTOSCALER DETAILED METRICS SUMMARY
===================================

Report generated: 2025-08-20 15:54:16

Total measurement records: 531
Deployments analyzed: 13
Time range: 40.00 - 605.00s
Simulation duration: 565.00s

OVERALL STATISTICS
==================
Average response time: 11115.06 ms
Max response time: 464485.33 ms
Average execution time: 2119.51 ms
Average wait time: 8995.55 ms
Average wait percentage: 7.12%
Total high wait count events: 1303
Average sample count: 23.6

PER-DEPLOYMENT BREAKDOWN
========================

Deployment: python-pi
  Measurement count: 39
  Time range: 40.0 - 605.0s
  Avg response time: 1198.05 ms
  Min/Max response time: 1048.88/1864.80 ms
  Avg execution time: 1086.19 ms
  Avg wait time: 111.85 ms
  Avg wait percentage: 6.94%
  High wait events: 392
  Avg sample count: 98.4
  Performance trend: improving

Deployment: python-pi-downtown
  Measurement count: 36
  Time range: 40.0 - 605.0s
  Avg response time: 967.42 ms
  Min/Max response time: 907.87/1463.20 ms
  Avg execution time: 914.71 ms
  Avg wait time: 52.71 ms
  Avg wait percentage: 3.98%
  High wait events: 81
  Avg sample count: 20.1
  Performance trend: improving

Deployment: python-pi-industrial
  Measurement count: 36
  Time range: 40.0 - 605.0s
  Avg response time: 997.55 ms
  Min/Max response time: 906.57/1926.07 ms
  Avg execution time: 912.77 ms
  Avg wait time: 84.78 ms
  Avg wait percentage: 4.92%
  High wait events: 82
  Avg sample count: 21.1
  Performance trend: improving

Deployment: python-pi-residential
  Measurement count: 36
  Time range: 40.0 - 605.0s
  Avg response time: 1480.70 ms
  Min/Max response time: 1054.84/4862.34 ms
  Avg execution time: 1120.65 ms
  Avg wait time: 360.05 ms
  Avg wait percentage: 8.03%
  High wait events: 79
  Avg sample count: 19.4
  Performance trend: improving

Deployment: python-pi-suburb
  Measurement count: 60
  Time range: 40.0 - 605.0s
  Avg response time: 1245.64 ms
  Min/Max response time: 1096.66/1327.31 ms
  Avg execution time: 1226.48 ms
  Avg wait time: 19.16 ms
  Avg wait percentage: 1.56%
  High wait events: 49
  Avg sample count: 19.2
  Performance trend: stable

Deployment: resnet50-inference
  Measurement count: 34
  Time range: 40.0 - 605.0s
  Avg response time: 666.26 ms
  Min/Max response time: 608.61/771.25 ms
  Avg execution time: 637.41 ms
  Avg wait time: 28.84 ms
  Avg wait percentage: 4.14%
  High wait events: 242
  Avg sample count: 77.3
  Performance trend: stable

Deployment: resnet50-inference-downtown
  Measurement count: 34
  Time range: 40.0 - 605.0s
  Avg response time: 746.09 ms
  Min/Max response time: 692.98/866.19 ms
  Avg execution time: 721.27 ms
  Avg wait time: 24.83 ms
  Avg wait percentage: 3.07%
  High wait events: 54
  Avg sample count: 17.3
  Performance trend: stable

Deployment: resnet50-inference-industrial
  Measurement count: 34
  Time range: 40.0 - 605.0s
  Avg response time: 763.72 ms
  Min/Max response time: 713.30/946.68 ms
  Avg execution time: 721.96 ms
  Avg wait time: 41.76 ms
  Avg wait percentage: 4.91%
  High wait events: 98
  Avg sample count: 20.1
  Performance trend: stable

Deployment: resnet50-inference-suburb
  Measurement count: 34
  Time range: 40.0 - 605.0s
  Avg response time: 760.58 ms
  Min/Max response time: 703.07/979.33 ms
  Avg execution time: 725.12 ms
  Avg wait time: 35.46 ms
  Avg wait percentage: 4.33%
  High wait events: 84
  Avg sample count: 20.4
  Performance trend: stable

Deployment: resnet50-preprocessing
  Measurement count: 20
  Time range: 75.0 - 600.0s
  Avg response time: 243969.74 ms
  Min/Max response time: 20843.49/464485.33 ms
  Avg execution time: 7656.52 ms
  Avg wait time: 236313.23 ms
  Avg wait percentage: 92.42%
  High wait events: 48
  Avg sample count: 2.4
  Performance trend: degrading

Deployment: speech-inference
  Measurement count: 64
  Time range: 40.0 - 605.0s
  Avg response time: 4176.09 ms
  Min/Max response time: 3724.30/5567.93 ms
  Avg execution time: 4031.73 ms
  Avg wait time: 144.36 ms
  Avg wait percentage: 2.86%
  High wait events: 62
  Avg sample count: 7.1
  Performance trend: stable

Deployment: speech-inference-downtown
  Measurement count: 54
  Time range: 40.0 - 605.0s
  Avg response time: 4028.37 ms
  Min/Max response time: 3714.43/7640.08 ms
  Avg execution time: 3815.26 ms
  Avg wait time: 213.11 ms
  Avg wait percentage: 3.23%
  High wait events: 22
  Avg sample count: 2.6
  Performance trend: stable

Deployment: speech-inference-suburb
  Measurement count: 50
  Time range: 40.0 - 600.0s
  Avg response time: 3850.93 ms
  Min/Max response time: 3738.16/4283.35 ms
  Avg execution time: 3815.93 ms
  Avg wait time: 35.00 ms
  Avg wait percentage: 0.84%
  High wait events: 10
  Avg sample count: 2.6
  Performance trend: stable

PERFORMANCE ANALYSIS
===================

Records with high wait percentage (>50%): 28
  speech-inference-downtown: 2 records, avg 50.4% wait
  python-pi-residential: 4 records, avg 71.2% wait
  python-pi-industrial: 2 records, avg 52.2% wait
  resnet50-preprocessing: 20 records, avg 92.4% wait

Records with high response times (>4205.2ms): 52
  speech-inference: 24 records, avg 4597.4ms
  speech-inference-downtown: 4 records, avg 6535.9ms
  python-pi-residential: 2 records, avg 4862.3ms
  resnet50-preprocessing: 20 records, avg 243969.7ms
  speech-inference-suburb: 2 records, avg 4283.4ms

SCALING RECOMMENDATIONS
======================

python-pi:
  ✅ ACCEPTABLE: Wait times within reasonable range

python-pi-downtown:
  🟢 GOOD: Low wait times - consider scaling down if consistent

python-pi-industrial:
  🟢 GOOD: Low wait times - consider scaling down if consistent

python-pi-residential:
  ✅ ACCEPTABLE: Wait times within reasonable range

python-pi-suburb:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-downtown:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-industrial:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-suburb:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-preprocessing:
  🔴 CRITICAL: Very high wait times - immediate scaling needed
  ⚠️  High response times detected - investigate bottlenecks

speech-inference:
  🟢 GOOD: Low wait times - consider scaling down if consistent

speech-inference-downtown:
  🟢 GOOD: Low wait times - consider scaling down if consistent

speech-inference-suburb:
  🟢 GOOD: Low wait times - consider scaling down if consistent

