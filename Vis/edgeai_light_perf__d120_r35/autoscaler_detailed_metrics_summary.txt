AUTOSCALER DETAILED METRICS SUMMARY
===================================

Report generated: 2025-08-05 15:13:51

Total measurement records: 710
Deployments analyzed: 13
Time range: 40.00 - 605.00s
Simulation duration: 565.00s

OVERALL STATISTICS
==================
Average response time: 2921.98 ms
Max response time: 48951.03 ms
Average execution time: 2036.51 ms
Average wait time: 885.47 ms
Average wait percentage: 4.52%
Total high wait count events: 698
Average sample count: 29.3

PER-DEPLOYMENT BREAKDOWN
========================

Deployment: fio
  Measurement count: 8
  Time range: 425.0 - 530.0s
  Avg response time: 1128.73 ms
  Min/Max response time: 1092.76/1145.68 ms
  Avg execution time: 1128.73 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 1.0
  Performance trend: stable

Deployment: fio-downtown
  Measurement count: 8
  Time range: 425.0 - 530.0s
  Avg response time: 1128.73 ms
  Min/Max response time: 1092.76/1145.68 ms
  Avg execution time: 1128.73 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 1.0
  Performance trend: stable

Deployment: python-pi
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 2547.72 ms
  Min/Max response time: 1063.59/15460.74 ms
  Avg execution time: 1184.71 ms
  Avg wait time: 1363.01 ms
  Avg wait percentage: 10.50%
  High wait events: 388
  Avg sample count: 95.1
  Performance trend: improving

Deployment: python-pi-downtown
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 2866.99 ms
  Min/Max response time: 1060.68/17570.02 ms
  Avg execution time: 1180.01 ms
  Avg wait time: 1686.98 ms
  Avg wait percentage: 10.67%
  High wait events: 126
  Avg sample count: 32.9
  Performance trend: improving

Deployment: python-pi-suburb
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 2610.06 ms
  Min/Max response time: 1029.19/15110.59 ms
  Avg execution time: 1217.16 ms
  Avg wait time: 1392.90 ms
  Avg wait percentage: 10.49%
  High wait events: 116
  Avg sample count: 30.9
  Performance trend: improving

Deployment: resnet50-inference
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 1131.77 ms
  Min/Max response time: 478.87/1747.38 ms
  Avg execution time: 1131.49 ms
  Avg wait time: 0.28 ms
  Avg wait percentage: 0.06%
  High wait events: 0
  Avg sample count: 72.2
  Performance trend: degrading

Deployment: resnet50-inference-downtown
  Measurement count: 66
  Time range: 40.0 - 605.0s
  Avg response time: 1094.36 ms
  Min/Max response time: 596.23/2120.37 ms
  Avg execution time: 1094.36 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 19.1
  Performance trend: degrading

Deployment: resnet50-inference-industrial
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 1114.75 ms
  Min/Max response time: 587.83/1658.48 ms
  Avg execution time: 1114.75 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 16.5
  Performance trend: degrading

Deployment: resnet50-inference-suburb
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 949.58 ms
  Min/Max response time: 378.49/1631.65 ms
  Avg execution time: 949.58 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 17.6
  Performance trend: stable

Deployment: resnet50-preprocessing
  Measurement count: 34
  Time range: 40.0 - 600.0s
  Avg response time: 16727.11 ms
  Min/Max response time: 6992.49/48951.03 ms
  Avg execution time: 7122.76 ms
  Avg wait time: 9604.35 ms
  Avg wait percentage: 31.00%
  High wait events: 68
  Avg sample count: 7.6
  Performance trend: improving

Deployment: speech-inference
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 3514.62 ms
  Min/Max response time: 2968.43/3872.69 ms
  Avg execution time: 3514.62 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 11.1
  Performance trend: stable

Deployment: speech-inference-downtown
  Measurement count: 56
  Time range: 40.0 - 605.0s
  Avg response time: 3379.00 ms
  Min/Max response time: 2675.29/3846.95 ms
  Avg execution time: 3379.00 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 4.4
  Performance trend: stable

Deployment: speech-inference-suburb
  Measurement count: 62
  Time range: 40.0 - 605.0s
  Avg response time: 3618.66 ms
  Min/Max response time: 3245.74/3863.82 ms
  Avg execution time: 3618.66 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 4.1
  Performance trend: stable

PERFORMANCE ANALYSIS
===================

Records with high wait percentage (>50%): 38
  resnet50-preprocessing: 14 records, avg 75.3% wait
  python-pi: 8 records, avg 89.2% wait
  python-pi-downtown: 8 records, avg 90.7% wait
  python-pi-suburb: 8 records, avg 89.2% wait

Records with high response times (>3826.0ms): 70
  resnet50-preprocessing: 34 records, avg 16727.1ms
  python-pi: 8 records, avg 12962.2ms
  python-pi-downtown: 8 records, avg 15817.0ms
  python-pi-suburb: 8 records, avg 13279.7ms
  speech-inference-suburb: 8 records, avg 3844.3ms
  speech-inference: 2 records, avg 3872.7ms
  speech-inference-downtown: 2 records, avg 3847.0ms

SCALING RECOMMENDATIONS
======================

fio:
  🟢 GOOD: Low wait times - consider scaling down if consistent

fio-downtown:
  🟢 GOOD: Low wait times - consider scaling down if consistent

python-pi:
  ✅ ACCEPTABLE: Wait times within reasonable range

python-pi-downtown:
  ✅ ACCEPTABLE: Wait times within reasonable range

python-pi-suburb:
  ✅ ACCEPTABLE: Wait times within reasonable range

resnet50-inference:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-downtown:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-industrial:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-suburb:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-preprocessing:
  ✅ ACCEPTABLE: Wait times within reasonable range
  ⚠️  High response times detected - investigate bottlenecks

speech-inference:
  🟢 GOOD: Low wait times - consider scaling down if consistent

speech-inference-downtown:
  🟢 GOOD: Low wait times - consider scaling down if consistent

speech-inference-suburb:
  🟢 GOOD: Low wait times - consider scaling down if consistent

