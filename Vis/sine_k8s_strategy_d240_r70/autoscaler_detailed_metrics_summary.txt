AUTOSCALER DETAILED METRICS SUMMARY
===================================

Report generated: 2025-08-19 05:47:07

Total measurement records: 99
Deployments analyzed: 3
Time range: 5.00 - 600.00s
Simulation duration: 595.00s

OVERALL STATISTICS
==================
Average response time: 26651.13 ms
Max response time: 301489.50 ms
Average execution time: 1675.16 ms
Average wait time: 24975.97 ms
Average wait percentage: 60.53%
Total high wait count events: 4234
Average sample count: 132.9

PER-DEPLOYMENT BREAKDOWN
========================

Deployment: python-pi
  Measurement count: 36
  Time range: 5.0 - 600.0s
  Avg response time: 53564.03 ms
  Min/Max response time: 1323.55/301489.50 ms
  Avg execution time: 1100.06 ms
  Avg wait time: 52463.96 ms
  Avg wait percentage: 92.45%
  High wait events: 2858
  Avg sample count: 199.2
  Performance trend: degrading

Deployment: resnet50-inference
  Measurement count: 35
  Time range: 5.0 - 600.0s
  Avg response time: 7899.84 ms
  Min/Max response time: 481.86/80804.30 ms
  Avg execution time: 856.37 ms
  Avg wait time: 7043.47 ms
  Avg wait percentage: 44.40%
  High wait events: 1244
  Avg sample count: 157.0
  Performance trend: degrading

Deployment: speech-inference
  Measurement count: 28
  Time range: 40.0 - 600.0s
  Avg response time: 15487.95 ms
  Min/Max response time: 3276.38/75975.61 ms
  Avg execution time: 3438.06 ms
  Avg wait time: 12049.89 ms
  Avg wait percentage: 39.65%
  High wait events: 132
  Avg sample count: 17.6
  Performance trend: improving

PERFORMANCE ANALYSIS
===================

Records with high wait percentage (>50%): 60
  resnet50-inference: 14 records, avg 90.0% wait
  python-pi: 34 records, avg 96.0% wait
  speech-inference: 12 records, avg 84.8% wait

Records with high response times (>76941.4ms): 10
  python-pi: 8 records, avg 148895.6ms
  resnet50-inference: 2 records, avg 80804.3ms

SCALING RECOMMENDATIONS
======================

python-pi:
  🔴 CRITICAL: Very high wait times - immediate scaling needed
  ⚠️  High response times detected - investigate bottlenecks

resnet50-inference:
  🟡 WARNING: Moderate wait times - consider scaling up

speech-inference:
  ✅ ACCEPTABLE: Wait times within reasonable range
  ⚠️  High response times detected - investigate bottlenecks

