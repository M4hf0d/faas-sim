AUTOSCALER DETAILED METRICS SUMMARY
===================================

Report generated: 2025-08-22 16:13:31

Total measurement records: 1419
Deployments analyzed: 13
Time range: 40.00 - 1510.00s
Simulation duration: 1470.00s

OVERALL STATISTICS
==================
Average response time: 21670.20 ms
Max response time: 733751.99 ms
Average execution time: 1980.86 ms
Average wait time: 19689.34 ms
Average wait percentage: 12.62%
Total high wait count events: 3630
Average sample count: 29.2

PER-DEPLOYMENT BREAKDOWN
========================

Deployment: python-pi
  Measurement count: 114
  Time range: 40.0 - 1480.0s
  Avg response time: 3986.09 ms
  Min/Max response time: 911.17/39521.23 ms
  Avg execution time: 1281.44 ms
  Avg wait time: 2704.65 ms
  Avg wait percentage: 15.21%
  High wait events: 1380
  Avg sample count: 101.1
  Performance trend: improving

Deployment: python-pi-downtown
  Measurement count: 112
  Time range: 40.0 - 1480.0s
  Avg response time: 2687.34 ms
  Min/Max response time: 918.16/17813.72 ms
  Avg execution time: 1238.83 ms
  Avg wait time: 1448.50 ms
  Avg wait percentage: 11.04%
  High wait events: 284
  Avg sample count: 20.8
  Performance trend: improving

Deployment: python-pi-industrial
  Measurement count: 110
  Time range: 40.0 - 1480.0s
  Avg response time: 4832.06 ms
  Min/Max response time: 912.82/39565.67 ms
  Avg execution time: 1365.83 ms
  Avg wait time: 3466.23 ms
  Avg wait percentage: 17.33%
  High wait events: 324
  Avg sample count: 20.5
  Performance trend: improving

Deployment: python-pi-residential
  Measurement count: 110
  Time range: 40.0 - 1480.0s
  Avg response time: 4875.90 ms
  Min/Max response time: 903.98/39476.78 ms
  Avg execution time: 1428.08 ms
  Avg wait time: 3447.82 ms
  Avg wait percentage: 17.45%
  High wait events: 326
  Avg sample count: 20.1
  Performance trend: improving

Deployment: python-pi-suburb
  Measurement count: 112
  Time range: 40.0 - 1480.0s
  Avg response time: 2734.33 ms
  Min/Max response time: 907.55/18807.88 ms
  Avg execution time: 1235.79 ms
  Avg wait time: 1498.54 ms
  Avg wait percentage: 11.05%
  High wait events: 286
  Avg sample count: 20.8
  Performance trend: improving

Deployment: resnet50-inference
  Measurement count: 116
  Time range: 40.0 - 1510.0s
  Avg response time: 553.56 ms
  Min/Max response time: 534.38/647.66 ms
  Avg execution time: 550.72 ms
  Avg wait time: 2.84 ms
  Avg wait percentage: 0.45%
  High wait events: 202
  Avg sample count: 92.2
  Performance trend: stable

Deployment: resnet50-inference-downtown
  Measurement count: 116
  Time range: 40.0 - 1510.0s
  Avg response time: 706.83 ms
  Min/Max response time: 627.11/961.59 ms
  Avg execution time: 700.24 ms
  Avg wait time: 6.59 ms
  Avg wait percentage: 0.71%
  High wait events: 114
  Avg sample count: 22.7
  Performance trend: stable

Deployment: resnet50-inference-industrial
  Measurement count: 114
  Time range: 40.0 - 1480.0s
  Avg response time: 728.12 ms
  Min/Max response time: 683.35/936.66 ms
  Avg execution time: 722.56 ms
  Avg wait time: 5.56 ms
  Avg wait percentage: 0.62%
  High wait events: 88
  Avg sample count: 22.4
  Performance trend: stable

Deployment: resnet50-inference-suburb
  Measurement count: 57
  Time range: 40.0 - 1480.0s
  Avg response time: 385.89 ms
  Min/Max response time: 375.13/399.42 ms
  Avg execution time: 385.89 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 23.6
  Performance trend: stable

Deployment: resnet50-preprocessing
  Measurement count: 80
  Time range: 75.0 - 1475.0s
  Avg response time: 335467.19 ms
  Min/Max response time: 23057.51/733751.99 ms
  Avg execution time: 6425.99 ms
  Avg wait time: 329041.20 ms
  Avg wait percentage: 95.52%
  High wait events: 410
  Avg sample count: 5.1
  Performance trend: degrading

Deployment: speech-inference
  Measurement count: 128
  Time range: 40.0 - 1480.0s
  Avg response time: 4175.87 ms
  Min/Max response time: 2570.23/13319.16 ms
  Avg execution time: 3539.44 ms
  Avg wait time: 636.43 ms
  Avg wait percentage: 5.92%
  High wait events: 130
  Avg sample count: 14.9
  Performance trend: improving

Deployment: speech-inference-downtown
  Measurement count: 124
  Time range: 40.0 - 1480.0s
  Avg response time: 4392.91 ms
  Min/Max response time: 3717.65/13486.97 ms
  Avg execution time: 3807.65 ms
  Avg wait time: 585.26 ms
  Avg wait percentage: 5.17%
  High wait events: 44
  Avg sample count: 4.9
  Performance trend: improving

Deployment: speech-inference-suburb
  Measurement count: 126
  Time range: 40.0 - 1480.0s
  Avg response time: 3592.75 ms
  Min/Max response time: 2570.23/12300.05 ms
  Avg execution time: 3107.29 ms
  Avg wait time: 485.46 ms
  Avg wait percentage: 4.99%
  High wait events: 42
  Avg sample count: 5.5
  Performance trend: improving

PERFORMANCE ANALYSIS
===================

Records with high wait percentage (>50%): 186
  speech-inference: 12 records, avg 63.1% wait
  speech-inference-downtown: 10 records, avg 64.2% wait
  speech-inference-suburb: 10 records, avg 62.9% wait
  python-pi: 16 records, avg 91.6% wait
  python-pi-downtown: 12 records, avg 90.5% wait
  python-pi-suburb: 12 records, avg 90.5% wait
  python-pi-industrial: 18 records, avg 87.7% wait
  python-pi-residential: 16 records, avg 92.3% wait
  resnet50-preprocessing: 80 records, avg 95.5% wait

Records with high response times (>13436.6ms): 142
  python-pi-downtown: 8 records, avg 15633.6ms
  python-pi-suburb: 10 records, avg 15589.9ms
  python-pi-industrial: 16 records, avg 24900.5ms
  python-pi-residential: 14 records, avg 26431.7ms
  python-pi: 10 records, avg 25165.0ms
  speech-inference-downtown: 4 records, avg 13464.6ms
  resnet50-preprocessing: 80 records, avg 335467.2ms

SCALING RECOMMENDATIONS
======================

python-pi:
  ✅ ACCEPTABLE: Wait times within reasonable range

python-pi-downtown:
  ✅ ACCEPTABLE: Wait times within reasonable range

python-pi-industrial:
  ✅ ACCEPTABLE: Wait times within reasonable range

python-pi-residential:
  ✅ ACCEPTABLE: Wait times within reasonable range

python-pi-suburb:
  ✅ ACCEPTABLE: Wait times within reasonable range

resnet50-inference:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-downtown:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-industrial:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-suburb:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-preprocessing:
  🔴 CRITICAL: Very high wait times - immediate scaling needed
  ⚠️  High response times detected - investigate bottlenecks

speech-inference:
  ✅ ACCEPTABLE: Wait times within reasonable range

speech-inference-downtown:
  ✅ ACCEPTABLE: Wait times within reasonable range

speech-inference-suburb:
  🟢 GOOD: Low wait times - consider scaling down if consistent

