AUTOSCALER DETAILED METRICS SUMMARY
===================================

Report generated: 2025-08-06 12:31:15

Total measurement records: 712
Deployments analyzed: 13
Time range: 40.00 - 605.00s
Simulation duration: 565.00s

OVERALL STATISTICS
==================
Average response time: 2860.36 ms
Max response time: 48951.03 ms
Average execution time: 2031.80 ms
Average wait time: 828.56 ms
Average wait percentage: 4.31%
Total high wait count events: 696
Average sample count: 28.9

PER-DEPLOYMENT BREAKDOWN
========================

Deployment: fio
  Measurement count: 8
  Time range: 425.0 - 530.0s
  Avg response time: 1128.73 ms
  Min/Max response time: 1092.76/1145.68 ms
  Avg execution time: 1128.73 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 1.0
  Performance trend: stable

Deployment: fio-downtown
  Measurement count: 8
  Time range: 425.0 - 530.0s
  Avg response time: 1128.73 ms
  Min/Max response time: 1092.76/1145.68 ms
  Avg execution time: 1128.73 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 1.0
  Performance trend: stable

Deployment: python-pi
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 2546.45 ms
  Min/Max response time: 1059.09/15460.74 ms
  Avg execution time: 1183.45 ms
  Avg wait time: 1363.00 ms
  Avg wait percentage: 10.50%
  High wait events: 388
  Avg sample count: 94.6
  Performance trend: improving

Deployment: python-pi-downtown
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 2865.79 ms
  Min/Max response time: 1057.07/17570.02 ms
  Avg execution time: 1178.81 ms
  Avg wait time: 1686.98 ms
  Avg wait percentage: 10.67%
  High wait events: 126
  Avg sample count: 32.5
  Performance trend: improving

Deployment: python-pi-suburb
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 2608.79 ms
  Min/Max response time: 998.56/15110.59 ms
  Avg execution time: 1215.89 ms
  Avg wait time: 1392.90 ms
  Avg wait percentage: 10.49%
  High wait events: 116
  Avg sample count: 30.7
  Performance trend: improving

Deployment: resnet50-inference
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 1124.49 ms
  Min/Max response time: 480.46/2026.21 ms
  Avg execution time: 1124.26 ms
  Avg wait time: 0.23 ms
  Avg wait percentage: 0.05%
  High wait events: 0
  Avg sample count: 71.4
  Performance trend: degrading

Deployment: resnet50-inference-downtown
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 1078.94 ms
  Min/Max response time: 619.08/2021.46 ms
  Avg execution time: 1078.94 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 18.1
  Performance trend: degrading

Deployment: resnet50-inference-industrial
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 1105.40 ms
  Min/Max response time: 585.63/2077.15 ms
  Avg execution time: 1105.40 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 16.3
  Performance trend: degrading

Deployment: resnet50-inference-suburb
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 962.96 ms
  Min/Max response time: 379.57/1858.67 ms
  Avg execution time: 962.96 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 17.4
  Performance trend: degrading

Deployment: resnet50-preprocessing
  Measurement count: 34
  Time range: 40.0 - 600.0s
  Avg response time: 15562.15 ms
  Min/Max response time: 6948.66/48951.03 ms
  Avg execution time: 7097.34 ms
  Avg wait time: 8464.80 ms
  Avg wait percentage: 26.80%
  High wait events: 66
  Avg sample count: 7.5
  Performance trend: improving

Deployment: speech-inference
  Measurement count: 68
  Time range: 40.0 - 605.0s
  Avg response time: 3486.34 ms
  Min/Max response time: 2916.46/4010.14 ms
  Avg execution time: 3486.34 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 10.7
  Performance trend: stable

Deployment: speech-inference-downtown
  Measurement count: 54
  Time range: 40.0 - 605.0s
  Avg response time: 3461.33 ms
  Min/Max response time: 2552.37/4686.77 ms
  Avg execution time: 3461.33 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 4.3
  Performance trend: stable

Deployment: speech-inference-suburb
  Measurement count: 64
  Time range: 40.0 - 605.0s
  Avg response time: 3586.08 ms
  Min/Max response time: 2663.02/3880.09 ms
  Avg execution time: 3586.08 ms
  Avg wait time: 0.00 ms
  Avg wait percentage: 0.00%
  High wait events: 0
  Avg sample count: 3.9
  Performance trend: stable

PERFORMANCE ANALYSIS
===================

Records with high wait percentage (>50%): 36
  resnet50-preprocessing: 12 records, avg 75.9% wait
  python-pi: 8 records, avg 89.2% wait
  python-pi-downtown: 8 records, avg 90.7% wait
  python-pi-suburb: 8 records, avg 89.2% wait

Records with high response times (>3866.0ms): 72
  resnet50-preprocessing: 34 records, avg 15562.1ms
  python-pi: 8 records, avg 12962.1ms
  python-pi-downtown: 8 records, avg 15817.0ms
  python-pi-suburb: 8 records, avg 13279.7ms
  speech-inference: 4 records, avg 3963.1ms
  speech-inference-suburb: 8 records, avg 3876.2ms
  speech-inference-downtown: 2 records, avg 4686.8ms

SCALING RECOMMENDATIONS
======================

fio:
  🟢 GOOD: Low wait times - consider scaling down if consistent

fio-downtown:
  🟢 GOOD: Low wait times - consider scaling down if consistent

python-pi:
  ✅ ACCEPTABLE: Wait times within reasonable range

python-pi-downtown:
  ✅ ACCEPTABLE: Wait times within reasonable range

python-pi-suburb:
  ✅ ACCEPTABLE: Wait times within reasonable range

resnet50-inference:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-downtown:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-industrial:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-inference-suburb:
  🟢 GOOD: Low wait times - consider scaling down if consistent

resnet50-preprocessing:
  ✅ ACCEPTABLE: Wait times within reasonable range
  ⚠️  High response times detected - investigate bottlenecks

speech-inference:
  🟢 GOOD: Low wait times - consider scaling down if consistent

speech-inference-downtown:
  🟢 GOOD: Low wait times - consider scaling down if consistent

speech-inference-suburb:
  🟢 GOOD: Low wait times - consider scaling down if consistent

