AUTOSCALER DETAILED METRICS SUMMARY
===================================

Report generated: 2025-08-18 11:40:12

Total measurement records: 82
Deployments analyzed: 3
Time range: 5.00 - 600.00s
Simulation duration: 595.00s

OVERALL STATISTICS
==================
Average response time: 44591.01 ms
Max response time: 371970.86 ms
Average execution time: 1951.42 ms
Average wait time: 42639.58 ms
Average wait percentage: 78.66%
Total high wait count events: 6828
Average sample count: 161.0

PER-DEPLOYMENT BREAKDOWN
========================

Deployment: python-pi
  Measurement count: 36
  Time range: 5.0 - 600.0s
  Avg response time: 65292.86 ms
  Min/Max response time: 1344.16/371970.86 ms
  Avg execution time: 1079.34 ms
  Avg wait time: 64213.52 ms
  Avg wait percentage: 93.58%
  High wait events: 3960
  Avg sample count: 254.8
  Performance trend: degrading

Deployment: resnet50-inference
  Measurement count: 14
  Time range: 5.0 - 215.0s
  Avg response time: 21751.70 ms
  Min/Max response time: 1149.92/46199.00 ms
  Avg execution time: 604.41 ms
  Avg wait time: 21147.30 ms
  Avg wait percentage: 92.89%
  High wait events: 2672
  Avg sample count: 248.0
  Performance trend: degrading

Deployment: speech-inference
  Measurement count: 32
  Time range: 40.0 - 600.0s
  Avg response time: 31293.62 ms
  Min/Max response time: 3202.16/173666.53 ms
  Avg execution time: 3521.84 ms
  Avg wait time: 27771.78 ms
  Avg wait percentage: 55.65%
  High wait events: 196
  Avg sample count: 17.4
  Performance trend: improving

PERFORMANCE ANALYSIS
===================

Records with high wait percentage (>50%): 68
  resnet50-inference: 14 records, avg 92.9% wait
  speech-inference: 20 records, avg 87.1% wait
  python-pi: 34 records, avg 97.2% wait

Records with high response times (>84813.8ms): 8
  python-pi: 6 records, avg 199719.7ms
  speech-inference: 2 records, avg 173666.5ms

SCALING RECOMMENDATIONS
======================

python-pi:
  🔴 CRITICAL: Very high wait times - immediate scaling needed
  ⚠️  High response times detected - investigate bottlenecks

resnet50-inference:
  🔴 CRITICAL: Very high wait times - immediate scaling needed
  ⚠️  High response times detected - investigate bottlenecks

speech-inference:
  🟡 WARNING: Moderate wait times - consider scaling up
  ⚠️  High response times detected - investigate bottlenecks

