=== RUNNING HYPOTHESIS TEST ===
Hypothesis: LPLT reduces power consumption vs Basic baseline, but increases response times

=== POWER CONSUMPTION COMPARISON ===
Basic average power: 3.1W
LPLT average power: 3.1W
Power savings: 1.3%

=== PERFORMANCE COMPARISON (ROBUST METRICS) ===
Basic MEDIAN response time: 1031.156s
LPLT MEDIAN response time: 1188.962s
MEDIAN performance penalty: 15.3%
Basic 95th percentile: 209089.070s
LPLT 95th percentile: 283085.220s
95th percentile penalty: 35.4%
Basic warm-up avg: 45356.073s
LPLT warm-up avg: 51902.516s
Warm-up performance penalty: 14.4%

=== WAIT TIME ANALYSIS ===
Basic median wait time: 6.269s
LPLT median wait time: 0.000s
Wait time improvement: 100.0%

=== REVISED HYPOTHESIS RESULT ===
✅ HYPOTHESIS CONFIRMED (MEDIAN): LPLT saves 1.3% energy
   at the cost of 15.3% slower median response times
🔍 DEEP ANALYSIS: Understanding Why LPLT Compares to Basic

=== NODE DISTRIBUTION ANALYSIS ===
Basic uses 116 unique nodes
LPLT uses 120 unique nodes
Node spreading difference: -4

Basic node load distribution:
  Average replicas per node: 10.3
  Max replicas on one node: 43
  Min replicas on one node: 4

LPLT node load distribution:
  Average replicas per node: 10.0
  Max replicas on one node: 18
  Min replicas on one node: 4

Consolidation factor: 0.98
➡️ Similar distribution patterns
=== COLD START ANALYSIS ===
Basic scheduling success rate: 0.7746478873239436
LPLT scheduling success rate: 0.6842105263157895

Cold start execution times:
Basic early median t_exec: 3.050s
LPLT early median t_exec: 2.909s
✅ LPLT has 4.6% faster cold starts

Total scheduling events:
Basic: 1067 scheduling events
LPLT: 1313 scheduling events
=== WORKLOAD-SPECIFIC PERFORMANCE ===

resnet50-inference (12608 vs 12600 samples):
  Median: Basic=0.697s, LPLT=0.735s (+5.4%)
  P95: Basic=5.313s, LPLT=6.259s (+17.8%)

fio (3256 vs 3945 samples):
  Median: Basic=167.383s, LPLT=158.597s (-5.2%)
  P95: Basic=479.522s, LPLT=471.422s (-1.7%)

speech-inference (1727 vs 1939 samples):
  Median: Basic=56.682s, LPLT=3.910s (-93.1%)
  P95: Basic=448.246s, LPLT=436.696s (-2.6%)

python-pi (15335 vs 15337 samples):
  Median: Basic=0.924s, LPLT=0.922s (-0.2%)
  P95: Basic=52.536s, LPLT=48.429s (-7.8%)

resnet50-training (170 vs 145 samples):
  Median: Basic=303.022s, LPLT=395.369s (+30.5%)
  P95: Basic=509.166s, LPLT=528.157s (+3.7%)
=== SCALING DECISION ANALYSIS ===
Basic scaling actions:
  Scale up: 271
  Scale down: 183
  No action: 271
  Total actions: 454

LPLT scaling actions:
  Scale up: 295
  Scale down: 11
  No action: 418
  Total actions: 306

High response time events (>1s):
Basic: 30 events
LPLT: 32 events

Node type selection frequency:
Basic preferences:
  rockpi: 173
  nuc: 72
  nano: 20
  nx: 6
LPLT preferences:
  nano: 169
  coral: 95
  nx: 31
=== RESOURCE CONTENTION ANALYSIS ===
Basic average utilization by node type:
           cpu_util  memory_util
node_type                       
coral      0.013488     0.011240
nano       0.018433     0.013824
nuc        0.023074     0.019229
nx         0.024616     0.017724
rockpi     0.055444     0.046203
rpi3       0.041107     0.034256

LPLT average utilization by node type:
           cpu_util  memory_util
node_type                       
coral      0.013041     0.010868
nano       0.017441     0.013081
nuc        0.023008     0.019174
nx         0.024292     0.017490
rockpi     0.042359     0.035299
rpi3       0.032871     0.027392

High CPU utilization events (>90%):
Basic: 0 events
LPLT: 0 events

Average power per active node:
Basic: 3.14W
LPLT: 3.10W

==================================================
HYPOTHESIS VALIDATION SUMMARY
==================================================
✅ H2: LPLT has faster cold start performance
✅ H3: LPLT scales more conservatively (less churn)

=== SUMMARY ===
Trade-off ratio: 1.3% energy savings for 15.3% performance cost
Plot saved as tradeoff_plot.png
