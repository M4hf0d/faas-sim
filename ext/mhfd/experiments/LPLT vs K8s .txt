=== RUNNING HYPOTHESIS TEST ===
Hypothesis: Kubernetes reduces power consumption vs LPLT baseline, but increases response times

=== POWER CONSUMPTION COMPARISON ===

🔋 LPLT Workload Analysis:
  coral_0: 12 replicas × 2.49W = 29.9W
  coral_1: 8 replicas × 2.41W = 19.3W
  coral_2: 8 replicas × 2.49W = 20.0W
  coral_3: 8 replicas × 2.42W = 19.3W
  nano_0: 4 replicas × 1.98W = 7.9W
  nano_1: 4 replicas × 2.00W = 8.0W
  nano_10: 7 replicas × 1.98W = 13.9W
  nano_11: 7 replicas × 1.98W = 13.8W
  nano_12: 8 replicas × 1.96W = 15.6W
  nano_13: 4 replicas × 2.06W = 8.3W
  nano_14: 4 replicas × 2.03W = 8.1W
  nano_15: 8 replicas × 1.92W = 15.3W
  nano_16: 4 replicas × 2.03W = 8.1W
  nano_17: 4 replicas × 1.92W = 7.7W
  nano_18: 8 replicas × 1.94W = 15.5W
  nano_19: 8 replicas × 1.93W = 15.5W
  nano_2: 4 replicas × 1.99W = 8.0W
  nano_20: 8 replicas × 1.96W = 15.7W
  nano_21: 8 replicas × 1.95W = 15.6W
  nano_22: 8 replicas × 1.97W = 15.7W
  nano_23: 4 replicas × 2.05W = 8.2W
  nano_24: 4 replicas × 2.04W = 8.2W
  nano_25: 4 replicas × 2.07W = 8.3W
  nano_26: 8 replicas × 1.93W = 15.4W
  nano_27: 4 replicas × 2.03W = 8.1W
  nano_28: 7 replicas × 1.99W = 13.9W
  nano_3: 4 replicas × 1.90W = 7.6W
  nano_4: 4 replicas × 2.08W = 8.3W
  nano_5: 4 replicas × 2.01W = 8.0W
  nano_6: 4 replicas × 2.01W = 8.0W
  nano_7: 4 replicas × 2.02W = 8.1W
  nano_8: 4 replicas × 2.02W = 8.1W
  nano_9: 8 replicas × 1.94W = 15.5W
  nuc_0: 18 replicas × 6.69W = 120.4W
  nuc_1: 19 replicas × 6.72W = 127.7W
  nuc_2: 23 replicas × 6.75W = 155.3W
  nx_0: 12 replicas × 8.13W = 97.6W
  nx_1: 17 replicas × 8.19W = 139.3W
  nx_10: 12 replicas × 7.31W = 87.7W
  nx_11: 12 replicas × 7.67W = 92.0W
  nx_12: 12 replicas × 7.89W = 94.6W
  nx_13: 12 replicas × 7.43W = 89.2W
  nx_2: 12 replicas × 8.10W = 97.3W
  nx_3: 8 replicas × 7.35W = 58.8W
  nx_4: 12 replicas × 7.54W = 90.5W
  nx_5: 12 replicas × 7.82W = 93.9W
  nx_6: 12 replicas × 8.02W = 96.2W
  nx_7: 12 replicas × 7.63W = 91.6W
  nx_8: 12 replicas × 8.23W = 98.7W
  nx_9: 12 replicas × 8.09W = 97.0W
  rockpi_0: 16 replicas × 3.32W = 53.2W
  rockpi_1: 12 replicas × 3.39W = 40.7W
  rockpi_10: 16 replicas × 3.32W = 53.1W
  rockpi_11: 21 replicas × 3.36W = 70.6W
  rockpi_12: 16 replicas × 3.26W = 52.1W
  rockpi_13: 8 replicas × 3.24W = 25.9W
  rockpi_14: 16 replicas × 3.30W = 52.8W
  rockpi_15: 12 replicas × 3.62W = 43.5W
  rockpi_16: 16 replicas × 3.29W = 52.7W
  rockpi_17: 12 replicas × 3.65W = 43.8W
  rockpi_18: 12 replicas × 3.71W = 44.5W
  rockpi_19: 16 replicas × 3.29W = 52.6W
  rockpi_2: 17 replicas × 3.40W = 57.9W
  rockpi_20: 12 replicas × 3.67W = 44.0W
  rockpi_21: 16 replicas × 3.28W = 52.5W
  rockpi_22: 17 replicas × 3.45W = 58.7W
  rockpi_23: 16 replicas × 3.35W = 53.6W
  rockpi_24: 12 replicas × 3.46W = 41.5W
  rockpi_25: 16 replicas × 3.37W = 54.0W
  rockpi_26: 17 replicas × 3.70W = 62.8W
  rockpi_27: 12 replicas × 3.67W = 44.1W
  rockpi_28: 16 replicas × 3.33W = 53.3W
  rockpi_29: 12 replicas × 3.72W = 44.6W
  rockpi_3: 12 replicas × 3.41W = 40.9W
  rockpi_30: 12 replicas × 3.20W = 38.4W
  rockpi_31: 12 replicas × 3.69W = 44.3W
  rockpi_32: 12 replicas × 3.43W = 41.1W
  rockpi_33: 12 replicas × 3.60W = 43.2W
  rockpi_4: 16 replicas × 3.35W = 53.5W
  rockpi_5: 16 replicas × 3.27W = 52.4W
  rockpi_6: 17 replicas × 3.75W = 63.7W
  rockpi_7: 12 replicas × 3.70W = 44.4W
  rockpi_8: 12 replicas × 3.20W = 38.4W
  rockpi_9: 12 replicas × 3.73W = 44.8W
  rpi3_0: 12 replicas × 1.47W = 17.7W
  rpi3_1: 12 replicas × 1.48W = 17.8W
  rpi3_10: 12 replicas × 1.50W = 18.0W
  rpi3_11: 12 replicas × 1.50W = 18.0W
  rpi3_12: 12 replicas × 1.65W = 19.8W
  rpi3_13: 12 replicas × 1.66W = 19.9W
  rpi3_14: 8 replicas × 1.66W = 13.3W
  rpi3_15: 12 replicas × 1.50W = 18.0W
  rpi3_16: 12 replicas × 1.51W = 18.1W
  rpi3_17: 12 replicas × 1.51W = 18.1W
  rpi3_18: 12 replicas × 1.53W = 18.3W
  rpi3_19: 12 replicas × 1.54W = 18.4W
  rpi3_2: 12 replicas × 1.49W = 17.8W
  rpi3_20: 12 replicas × 1.54W = 18.5W
  rpi3_21: 12 replicas × 1.42W = 17.1W
  rpi3_22: 12 replicas × 1.43W = 17.2W
  rpi3_23: 12 replicas × 1.44W = 17.3W
  rpi3_24: 12 replicas × 1.54W = 18.5W
  rpi3_25: 17 replicas × 1.54W = 26.2W
  rpi3_26: 17 replicas × 1.55W = 26.3W
  rpi3_27: 12 replicas × 1.45W = 17.4W
  rpi3_28: 12 replicas × 1.46W = 17.5W
  rpi3_29: 12 replicas × 1.47W = 17.6W
  rpi3_3: 8 replicas × 1.40W = 11.2W
  rpi3_30: 12 replicas × 1.63W = 19.5W
  rpi3_31: 17 replicas × 1.63W = 27.7W
  rpi3_32: 12 replicas × 1.63W = 19.6W
  rpi3_33: 12 replicas × 1.52W = 18.2W
  rpi3_34: 12 replicas × 1.52W = 18.2W
  rpi3_35: 12 replicas × 1.52W = 18.3W
  rpi3_4: 8 replicas × 1.41W = 11.3W
  rpi3_5: 8 replicas × 1.42W = 11.3W
  rpi3_6: 12 replicas × 1.64W = 19.7W
  rpi3_7: 12 replicas × 1.64W = 19.7W
  rpi3_8: 12 replicas × 1.65W = 19.8W
  rpi3_9: 12 replicas × 1.49W = 17.9W
  Total: 4451.6W across 1338 replicas = 3.33W/replica

🔋 Kubernetes Workload Analysis:
  coral_0: 4 replicas × 2.52W = 10.1W
  coral_1: 74 replicas × 2.53W = 187.0W
  coral_2: 59 replicas × 2.54W = 150.1W
  coral_3: 64 replicas × 2.55W = 163.1W
  nano_0: 4 replicas × 1.91W = 7.6W
  nano_1: 4 replicas × 1.90W = 7.6W
  nano_12: 4 replicas × 1.97W = 7.9W
  nano_15: 4 replicas × 1.91W = 7.6W
  nano_17: 4 replicas × 1.91W = 7.6W
  nano_2: 4 replicas × 1.97W = 7.9W
  nano_3: 78 replicas × 2.02W = 157.9W
  nano_4: 78 replicas × 2.02W = 157.9W
  nano_5: 79 replicas × 2.02W = 159.9W
  nano_7: 84 replicas × 1.97W = 165.7W
  nano_8: 78 replicas × 2.02W = 157.9W
  nx_0: 8 replicas × 5.03W = 40.2W
  nx_10: 4 replicas × 5.38W = 21.5W
  nx_12: 73 replicas × 5.00W = 365.0W
  nx_13: 4 replicas × 5.38W = 21.5W
  nx_14: 84 replicas × 5.42W = 455.3W
  nx_4: 84 replicas × 5.42W = 455.3W
  nx_7: 84 replicas × 5.41W = 454.6W
  rockpi_11: 153 replicas × 3.05W = 465.9W
  rockpi_16: 8 replicas × 3.00W = 24.0W
  rockpi_23: 8 replicas × 3.00W = 24.0W
  rockpi_24: 25 replicas × 3.33W = 83.1W
  rockpi_25: 8 replicas × 3.00W = 24.0W
  rockpi_30: 8 replicas × 3.00W = 24.0W
  rockpi_33: 123 replicas × 3.08W = 378.9W
  rockpi_4: 248 replicas × 3.05W = 755.2W
  rockpi_5: 70 replicas × 3.08W = 215.6W
  rpi3_21: 8 replicas × 2.10W = 16.8W
  rpi3_22: 4 replicas × 2.10W = 8.4W
  rpi3_23: 4 replicas × 2.12W = 8.5W
  rpi3_27: 4 replicas × 2.12W = 8.5W
  rpi3_28: 4 replicas × 2.12W = 8.5W
  rpi3_29: 89 replicas × 2.12W = 189.0W
  Total: 5403.4W across 1727 replicas = 3.13W/replica
📊 TOTAL INFRASTRUCTURE POWER:
LPLT average total system power: 369.5W
Kubernetes average total system power: 520.6W
Infrastructure power savings: -40.9%

⚡ WORKLOAD ENERGY EFFICIENCY:
LPLT: 3.33W per replica
Kubernetes: 3.13W per replica
Workload efficiency improvement: 6.0%
✅ Kubernetes is more energy-efficient per replica

=== PERFORMANCE COMPARISON ===
LPLT MEDIAN response time: 1014.837s
Kubernetes MEDIAN response time: 1518.856s
MEDIAN performance penalty: 49.7%
LPLT 95th percentile: 50223.483s
Kubernetes 95th percentile: 8678.230s
95th percentile penalty: -82.7%
LPLT warm-up avg: 9892.229s
Kubernetes warm-up avg: 13660.200s
Warm-up performance penalty: 38.1%

=== WAIT TIME ANALYSIS ===
LPLT median wait time: 0.000s
Kubernetes median wait time: 0.000s
Wait time improvement: 0.0%

=== REVISED HYPOTHESIS RESULT ===
❌ HYPOTHESIS NOT CONFIRMED
   Power savings: -40.9%, Efficiency improvement: 6.0%
🔍 DEEP ANALYSIS: Understanding Why Kubernetes Compares to LPLT

=== NODE DISTRIBUTION ANALYSIS ===
LPLT uses 120 unique nodes
Kubernetes uses 37 unique nodes
Node spreading difference: 83

LPLT node load distribution:
  Average replicas per node: 11.2
  Max replicas on one node: 23
  Min replicas on one node: 4

Kubernetes node load distribution:
  Average replicas per node: 46.7
  Max replicas on one node: 248
  Min replicas on one node: 4

Consolidation factor: 4.19
✅ Kubernetes is consolidating workload (higher density per node)
=== COLD START ANALYSIS ===
LPLT scheduling success rate: 0.6853002070393375
Kubernetes scheduling success rate: 1.0

Cold start execution times:
LPLT early median t_exec: 2.886s
Kubernetes early median t_exec: 2.076s
✅ Kubernetes has 28.1% faster cold starts

Total scheduling events:
LPLT: 1451 scheduling events
Kubernetes: 1065 scheduling events
=== WORKLOAD-SPECIFIC PERFORMANCE ===

resnet50-inference (12590 vs 7167 samples):
  Median: LPLT=0.740s, Kubernetes=0.680s (-8.2%)
  P95: LPLT=5.782s, Kubernetes=0.815s (-85.9%)

fio (4039 vs 256 samples):
  Median: LPLT=155.743s, Kubernetes=279.672s (+79.6%)
  P95: LPLT=470.769s, Kubernetes=512.551s (+8.9%)

speech-inference (2458 vs 1856 samples):
  Median: LPLT=3.852s, Kubernetes=3.828s (-0.6%)
  P95: LPLT=265.515s, Kubernetes=11.475s (-95.7%)

python-pi (15336 vs 8935 samples):
  Median: LPLT=0.922s, Kubernetes=1.619s (+75.6%)
  P95: LPLT=48.500s, Kubernetes=6.827s (-85.9%)

resnet50-training (146 vs 18 samples):
  Median: LPLT=304.498s, Kubernetes=433.975s (+42.5%)
  P95: LPLT=515.046s, Kubernetes=579.715s (+12.6%)
=== SCALING DECISION ANALYSIS ===
LPLT scaling actions:
  Scale up: 327
  Scale down: 17
  No action: 380
  Total actions: 344

Kubernetes scaling actions:
  Scale up: 339
  Scale down: 787
  No action: 810
  Total actions: 1126

High response time events (>1s):
LPLT: 25 events
Kubernetes: 203 events

Node type selection frequency:
LPLT preferences:
  rockpi: 268
  coral: 52
  rpi3: 5
  nano: 2
Kubernetes preferences:
  nuc: 238
  rockpi: 67
  nx: 34
=== RESOURCE CONTENTION ANALYSIS ===
LPLT average utilization by node type:
           cpu_util  memory_util
node_type                       
coral      0.013041     0.010868
nano       0.017464     0.013098
nuc        0.023008     0.019174
nx         0.024321     0.017511
rockpi     0.034851     0.029042
rpi3       0.030479     0.025399

Kubernetes average utilization by node type:
           cpu_util  memory_util
node_type                       
coral      0.033616     0.028013
nano       0.097964     0.073473
nuc        0.120000     0.100000
nx         0.139819     0.100670
rockpi     0.093884     0.078236
rpi3       0.100909     0.084090

High CPU utilization events (>90%):
LPLT: 0 events
Kubernetes: 0 events

Average power per active node:
LPLT: 3.08W
Kubernetes: 4.37W

==================================================
HYPOTHESIS VALIDATION SUMMARY
==================================================
✅ H1: Kubernetes consolidates workload better than LPLT
✅ H2: Kubernetes has faster cold start performance

============================================================
🔍 DETAILED WORKLOAD ANALYSIS VALIDATION
==================================================

📊 LPLT Detailed Breakdown:
Workload distribution by node type:
  rockpi: 481 replicas × 3.46W = 1662.1W
  rpi3: 431 replicas × 1.53W = 657.6W
  nx: 169 replicas × 7.81W = 1320.7W
  nano: 161 replicas × 1.99W = 320.2W
  nuc: 60 replicas × 6.72W = 403.3W
  coral: 36 replicas × 2.45W = 88.3W

LPLT Summary:
  Total replicas: 1338
  Total workload power: 4451.6W
  Average efficiency: 3.327W per replica
  Unique nodes used: 10

📊 Kubernetes Detailed Breakdown:
Workload distribution by node type:
  rockpi: 651 replicas × 3.48W = 2263.7W
  nano: 421 replicas × 2.34W = 985.5W
  nx: 341 replicas × 7.92W = 2700.5W
  coral: 201 replicas × 2.60W = 522.8W
  rpi3: 113 replicas × 2.37W = 267.5W

Kubernetes Summary:
  Total replicas: 1727
  Total workload power: 5403.4W
  Average efficiency: 3.129W per replica
  Unique nodes used: 15

🎯 COMPARATIVE ANALYSIS:
Workload efficiency improvement: 6.0%
Total workload power reduction: -21.4%
Replica count difference: 1338 vs 1727

✅ VALIDATION CHECKS:
✓ Kubernetes has better energy efficiency per replica
✗ LPLT uses less total workload power

=== SUMMARY ===
Infrastructure power savings: -40.9%
Workload efficiency improvement: 6.0%
Performance trade-off: 49.7% response time penalty
Plot saved as tradeoff_plot.png
